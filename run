
import argparse  
import random  
import numpy as np  
import torch  

from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast

if __name__ == '__main__':

    # fix_seed = 2021  
    # random.seed(fix_seed)  
    # torch.manual_seed(fix_seed)  
    # np.random.seed(fix_seed)  

    torch.set_num_threads(6)  # 设置 PyTorch 使用的 CPU 线程数，以优化性能

    # --- 2. 初始化命令行参数解析器 ---
    parser = argparse.ArgumentParser(description='KeepChange')  # 创建解析器对象，并提供描述信息

    # --- 3. 定义所有可配置的命令行参数 ---

    # A. 基础配置
    parser.add_argument('--grid_size', type=int, default=4, help='KAN模型中的网格大小')
    parser.add_argument('--task_name', type=str, default='long_term_forecast',
                        help='任务名称, 可选: [long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')
    parser.add_argument('--is_training', type=int, default=1, help='状态标志, 1表示训练模式, 0表示测试模式')
    parser.add_argument('--model_id', type=str, default='train', help='模型的ID, 用于区分不同的实验')
    parser.add_argument('--model', type=str, default='DecompPatchTST',
                        help='要使用的模型名称')

    # B. 数据加载器配置
    parser.add_argument('--data', type=str, default='ETTh1', help='数据集类型')
    parser.add_argument('--root_path', type=str, default='E:/pycharm_code/KANMTS-mainzxt/KANMTS-main/KANMTS-main/iMyNewModel/', help='数据文件的根目录路径')
    parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='数据文件的具体名称')
    parser.add_argument('--features', type=str, default='M',
                        help='预测任务类型, 可选:[M, S, MS]; M:多变量预测多变量, S:单变量预测单变量, MS:多变量预测单变量')
    parser.add_argument('--target', type=str, default='OT', help='在S或MS任务中的目标特征列名')
    parser.add_argument('--freq', type=str, default='t',
                        help='时间特征编码的频率, 可选:[s:秒, t:分钟, h:小时, d:天, b:工作日, w:周, m:月]')
    parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='保存模型检查点的路径')

    # C. 预测任务相关配置
    parser.add_argument('--seq_len', type=int, default=96, help='输入序列的长度')
    parser.add_argument('--label_len', type=int, default=24, help='解码器输入的起始令牌长度（通常是输入序列的一部分）')
    parser.add_argument('--pred_len', type=int, default=96, help='需要预测的序列长度')
    parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='用于M4数据集的季节性模式子集')

    # D. 模型定义相关超参数
    parser.add_argument('--enc_in', type=int, default=7, help='编码器输入尺寸（特征维度）')

    parser.add_argument('--dec_in', type=int, default=7, help='解码器输入尺寸（特征维度）')
    parser.add_argument('--c_out', type=int, default=7, help='输出尺寸（预测的目标特征维度）')
    parser.add_argument('--d_model', type=int, default=512, help='模型的主维度（隐藏层大小）')
    parser.add_argument('--d_core', type=int, default=128, help='核心维度, 用于下采样, 需小于d_model')
    parser.add_argument('--e_layers', type=int, default=2, help='编码器的层数')
    parser.add_argument('--num_layers', type=int, default=2, help='通道混合层的层数')
    parser.add_argument('--d_layers', type=int, default=2, help='解码器的层数')
    parser.add_argument('--d_ff', type=int, default=512, help='前馈神经网络的维度')
    parser.add_argument('--moving_avg', type=int, default=75, help='移动平均的窗口大小')
    parser.add_argument('--factor', type=int, default=1, help='注意力机制的因子')
    parser.add_argument('--distil', action='store_false',
                        help='是否在编码器中使用蒸馏操作, 使用此参数表示不使用',
                        default=True)
    parser.add_argument('--dropout', type=float, default=0., help='Dropout的比率')
    parser.add_argument('--embed', type=str, default='timeF',
                        help='时间特征编码方式, 可选:[timeF, fixed, learned]')
    parser.add_argument('--activation', type=str, default='gelu', help='激活函数类型')
    parser.add_argument('--output_attention', action='store_true', help='是否在编码器中输出注意力权重')
    parser.add_argument('--attention_type', type=str, default="full", help='Transformer的注意力类型')
    parser.add_argument('--use_norm', type=int, default=1, help='是否对数据进行归一化和反归一化处理')
    # E. 优化与训练配置
    parser.add_argument('--num_workers', type=int, default=4, help='数据加载器使用的工作线程数')
    parser.add_argument('--itr', type=int, default=1, help='实验重复次数')
    parser.add_argument('--train_epochs', type=int, default=20, help='训练的总轮数')
    parser.add_argument('--batch_size', type=int, default=32, help='训练数据的批次大小')
    parser.add_argument('--patience', type=int, default=3,
                        help='提前停止的耐心值（连续patience轮验证集性能未提升则停止）')
    parser.add_argument('--learning_rate', type=float, default=0.0001, help='优化器的学习率')
    parser.add_argument('--des', type=str, default='test', help='实验描述')
    parser.add_argument('--loss', type=str, default='MAE', help='损失函数类型')
    parser.add_argument('--lradj', type=str, default='type1', help='学习率调整策略')
    parser.add_argument('--use_amp', action='store_true', help='是否使用自动混合精度训练', default=False)

    # F. GPU 配置
    parser.add_argument('--use_gpu', type=bool, default=True, help='是否使用GPU')
    parser.add_argument('--gpu', type=int, default=0, help='要使用的单个GPU的ID')
    parser.add_argument('--use_multi_gpu', action='store_true', help='是否使用多个GPU', default=False)
    parser.add_argument('--devices', type=str, default='0,1,2,3', help='多GPU模式下使用的设备ID列表')

    # G. 其他模型特定参数
    parser.add_argument('--save_model', action='store_true', help='是否保存模型')
    parser.add_argument('--hidden_dim', type=int, default=20, help='隐藏层维度')
    parser.add_argument('--n_layers', type=int, default=2, help='层数')


    #

    # --- 4. 解析参数并设置运行环境 ---
    args = parser.parse_args()  # 解析上面定义的所有命令行参数

    # 检查CUDA是否可用，并据此决定是否真正使用GPU
    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False

    # 如果使用多GPU，则解析设备ID
    if args.use_gpu and args.use_multi_gpu:
        args.devices = args.devices.replace(' ', '')  # 去除设备ID字符串中的空格
        device_ids = args.devices.split(',')  # 按逗号分割成列表
        args.device_ids = [int(id_) for id_ in device_ids]  # 转换为整数列表
        args.gpu = args.device_ids[0]  # 将主GPU设为列表中的第一个

    print('Args in experiment:')
    print(args)  # 打印所有参数配置，方便调试和记录

    # 将实验类赋值给一个更简洁的变量名
    Exp = Exp_Long_Term_Forecast


    # --- 5. 定义训练和测试的辅助函数 ---
    def train(args=args):
        """
        封装了训练和测试流程的函数。
        """
        # 构建一个唯一的字符串来标识本次实验的配置，用于保存模型和日志
        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_dc{}_el{}_dl{}_df{}_fc{}_dt{}_{}_nl{}_hd{}_bs{}_lr{}_te{}_gs{}'.format(
            args.task_name,
            args.model_id,
            args.model,
            args.data,
            args.features,
            args.seq_len,
            args.label_len,
            args.pred_len,
            args.d_model,
            args.d_core,
            args.e_layers,
            args.d_layers,
            args.d_ff,
            args.factor,
            args.distil,
            args.des,
            args.num_layers,
            args.hidden_dim,
            args.batch_size,
            args.learning_rate,
            args.train_epochs,
            args.grid_size
        )

        exp = Exp(args)  # 根据参数初始化实验对象

        # 将实验设置写入结果文件，方便追溯
        with open('./result/results.txt', 'a', encoding='utf-8', errors='replace') as file:
            file.write(f'setting: {setting}\n')

        # 执行训练
        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))
        exp.train(setting)

        # 训练结束后执行测试
        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))
        exp.test(setting)

        # 清空PyTorch的CUDA缓存，释放不必要的GPU内存
        torch.cuda.empty_cache()


    # --- 6. 主逻辑：根据 is_training 参数决定执行流程 ---
    if args.is_training:
        # 如果是训练模式，则调用 train 函数
        train(args)
    else:
        # 如果是测试模式，只进行测试
        # 构建与预训练模型相匹配的设置字符串
        setting = '{}_{}_{}_{}_ft{}_sl{}_pl{}_dm{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(
            args.task_name,
            args.model_id,
            args.model,
            args.data,
            args.features,
            args.seq_len,

            args.pred_len,
            args.d_model,
            args.e_layers,
            args.d_layers,
            args.d_ff,
            args.factor,
            args.embed,
            args.distil,
            args.des)

        exp = Exp(args)  # 初始化实验对象
        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))

        # 调用 test 方法，test=1 可能用于区分是独立测试还是训练后的测试
        exp.test(setting, test=1)
        torch.cuda.empty_cache()

        # 打印GPU内存使用情况，用于调试
        print(f"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB")
        print(f"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1024 ** 2:.2f} MB")
